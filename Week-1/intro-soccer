# -*- coding: utf-8 -*-
"""
nrwade0
3/18/19
"""

"""
Import libraries:
sqllite3 for interacting with local relational databases
pandas and numpy for data ingestion and manipulation
matplotlib for visualization
sklearn for machine learning tools
customplot.py for custom functions
"""
import sqlite3
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import scale
from customplot import pd_centers, parallel_plot


"""
Ingest FIFA soccer stats data
"""
cnx = sqlite3.connect('database.sqlite')
# df is a variable pointer to a pandas data frame.
df = pd.read_sql_query("Select * from Player_Attributes", cnx)


"""
Exploring data
"""
# gander at the data columns
df.columns
# display simple statistics
df.describe().transpose()


"""
Data cleaning: Handling missing data
"""
# Any null row?
df.isnull().any().any(), df.shape
# Any null column?
df.isnull().sum(axis = 0)


"""
Fixing null values, find and delete
"""
# take initial no. of rows
rows = df.shape[0]
# drop null rows
df = df.dropna()

# Check if null rows are gone
df.isnull().any().any(), df.shape
# how many null rows were deleted?
rows - df.shape[0]

# Shuffle rows to allow for better sampling
df = df.reindex(np.random.permutation(df.index))


"""
Predicting 'overall_rating' of a player
"""
# looking at top few rows
df.head(5)
# using pandas column to plot
df[:10][['penalties', 'overall_rating']]

# check if penalties feature is correlated to overall_rating
df['overall_rating'].corr(df['penalties'])
# = 0.39; this values goes from -1 to +1 with 0 meaning no correlation

# Create a list of potential features to measure correlation with
potentialFeatures = ['acceleration', 'curve', 'free_kick_accuracy',
                     'ball_control', 'shot_power', 'stamina']
# Check correlations
for f in potentialFeatures:
    related = df['overall_rating'].corr(df[f])
    print("%s: %f" %(f, related))
    # ball_control and shot_power have the highest correlation


"""
Data visualization, plot correlations
"""
# list of all features to test correlation
cols = ['potential', 'crossing', 'finishing', 'heading_accuracy',
        'short_passing', 'volleys', 'dribbling', 'curve', 'free_kick_accuracy',
        'long_passing', 'ball_control', 'acceleration', 'sprint_speed', 
        'agility', 'reactions', 'balance', 'shot_power', 'jumping', 'stamina',
        'strength', 'long_shots', 'aggression', 'interceptions', 'positioning',
        'vision', 'penalties', 'marking', 'standing_tackle', 'sliding_tackle',
        'gk_diving', 'gk_handling', 'gk_kicking', 'gk_positioning',
        'gk_reflexes']
# create list of all correlations

correlations = [ df['overall_rating'].corr(df[f]) for f in cols ]

# create function for plotting a dataframe with string cols and numeric rows
def plot_dataframe(df, y_label):
    color = 'coral'
    fig = plt.gcf()
    fig.set_size_inches(20, 12)
    plt.ylabel(y_label)
    
    ax = df2.correlation.plot(linewidth = 3.3, color = color)
    ax.set_xticks(df2.index)
    ax.set_xticklabels(df2.attributes, rotation = 75); # note ;
    plt.show()

# create a dataframe using cols and correlations
df2 = pd.DataFrame({'attributes': cols, 'correlation': correlations})
# call dataframe plot function
plot_dataframe(df2, 'Player\'s Overall Rating')
# Analysis of findings: Suppose you have to predict a player's overall rating.
# Which 5 player attributes would you ask for?
# Go for highest correlation coefficients: potential, reactions, vision, short
# passing and ball control.


"""
Clustering players into similar groups
"""
# Define the features to group the players
select5features = ['gk_kicking', 'potential', 'marking', 'interceptions', 
                   'standing_tackle']
# Generate a new dataframe by selecting the features defined
df_select = df[select5features].copy(deep = True)

# KMeans clustering: machine learning method 
# is a method of vector quantization, originally from signal processing, that
# is popular for cluster analysis in data mining. k-means clustering aims to
# partition n observations into k clusters in which each observation belongs
# to the cluster with the nearest mean, serving as a prototype of the cluster.
# This results in a partitioning of the data space into Voronoi cells. 

# Perform scaling on the dataframe containing the features
data = scale(df_select)
# No. of clusters
Nclusters = 4
# Train a model
model = KMeans(init = 'k-means++', n_clusters = Nclusters, 
               n_init = 20).fit(data)

# output no. of players in each cluster
print(30*'_')
print("\nCount of players in each cluster")
print(30*'_')
print(pd.value_counts(model.labels_, sort = False))

# create a composite dataframe for plotting
# ... use custom function declared in customplot.py

P = pd_centers(featuresUsed = select5features, centers = model.cluster_centers_)
#print(P)


"""
Cluster visualization
"""
# Given 4 clusters based on selected features, these can be treated as profiles
# of similar players. Visualize by plotting the centers of each cluster, i.e.
# average values for each feature within the cluster.
parallel_plot(P)
# Analysis of findings: Can you identify the groups for each of the below?
#  1. Two groups are very similar except in gk_kicking - these players can
#               coach each other on gk_kicking, where they differ.
#  2. Two groups are somewhat similar to each other except in potential
# 
# 1. clusters 0 and 1 are similar in gk_kicking.
# 2. clusters 1 and 2 are similar, other than in potential.
